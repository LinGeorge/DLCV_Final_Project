"""
vit_fasttext.ipynb

Automatically generated by Colaboratory.

共有四個位置有"ABLATION" TAG
1. pretrained weight(supervised or SSL) 路徑修改/整段註解
2. CrossEntropy or LabelSmoothing 二選一
3. LabelSmooth/CELoss + FastText + LDAM 註解掉沒用到的損失函數
4. MixUp 選擇註解/不註解

"""

########################################################################
"""# Import Packages"""
########################################################################
import os
import sys
import random
import shutil
import time
import warnings
import PIL
import math
import csv
from typing import Callable, Iterable, Optional, Tuple, Union

from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib import cm
from sklearn.manifold import TSNE
import numpy as np

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.nn.functional as F
import torch.backends.cudnn as cudnn

import torch.distributed as dist
import torch.optim
import torch.multiprocessing as mp

import torch.optim as optim
from torch.optim import Optimizer
from torch.optim.lr_scheduler import LambdaLR
import torch.utils.data
import torch.utils.data.distributed
from torch.utils.data import Dataset, DataLoader

import torchvision
import torchvision.models as models
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torchvision.transforms.transforms import InterpolationMode
from torchvision.datasets import DatasetFolder
from torchvision import models
import torchvision.utils as vutils

from torch.autograd import Variable
from torch.autograd import Function

#!pip install https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip
from torchsampler import ImbalancedDatasetSampler

#!pip install timm
import timm

# Commented out IPython magic to ensure Python compatibility.
# if not os.path.exists('./fastText'):
#     !git clone https://github.com/facebookresearch/fastText.git
# #     %cd fastText
#     !pip install .
# #     %cd ..
import fasttext
import fasttext.util

########################################################################
"""# Fix Seeds"""
########################################################################
# fix random seeds
def fix_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    print('Seeds are now fixed.')

fix_seeds(0)

########################################################################
"""# Configurations""" # Contain 3.Auto Augmentation
########################################################################
# the configuration dictionary for p1
cfg = {
    # the cfg['DEVICE'] to be used for training and validation
    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',
    
    # the prefix for avoiding overwriting when backuping the checkpoint and output csv-files
    'BACKUP_PREFIX': 'nowd',
    
    # the number of classes
    'N_CLS': 1000,

    # the batch-size
    'BATCH_SZ': 32,
    
    # the number of epochs during training
    'N_EPOCHS': 10,

    # the name of the pretrained model under torchvision to be used
    'PRETRAINED_MODEL_NAME': 'resnet50',
    
    # the name of the optimizer used in training
    'OPTIM_NAME': 'Adam',
    
    # some parameters of the used optimizer
    'OPTIM_PARAMS': {
        'lr': 0.00005,
        # 'weight_decay': 1e-3,
    },
    
    # to determine whether to use lr-scheduler or not
    'USE_SCHED': True,
    
    # the name of the lr-scheduler used in training
    'SCHED_NAME': 'ReduceLROnPlateau',

    # the max-norm used in gradients clipping
    'MAX_NORM': 1,
    
    # some parameters of the used lr-scheduler
    'SCHED_PARAMS': {
        'factor': 0.5,
        'patience': 1,
        'min_lr': 1e-8,
    },
    
    # the directory of all data, including training, validation, and testing data
    'DATA_DIR': './food_data/',

    # the path to label2name.txt
    'LABEL2NAME_PATH': './food_data/label2name.txt',
    
    # the filename of the output csv-file
    'OUTPUT_CSV_FILENAME': 'submission.csv',
    
    # the file-paths of all four sample submission csv-files
    'SAMPLE_SUBMISSION_FILEPATHS': {
        'main': './food_data/testcase/sample_submission_main_track.csv',
        'freq': './food_data/testcase/sample_submission_freq_track.csv',
        'comm': './food_data/testcase/sample_submission_comm_track.csv',
        'rare': './food_data/testcase/sample_submission_rare_track.csv',
    },
    
    # the directory of the saved models
    'MODEL_SAVE_DIR': './saved_models',
    
    # the path of the pretrained word embedding model
    # 'PRETRAINED_WORD_EMBEDDING_MODEL_PATH': './y_360W_cbow_2D_300dim_2020v1.bin',
    'PRETRAINED_WORD_EMBEDDING_MODEL_PATH': './tmunlp_1.6B_WB_300dim_2020v1.bin',
    
    # the transforms for training (data augmentation)
    'TR_TFMS': transforms.Compose([
        # transforms.ToPILImage(),
        transforms.RandomRotation(20),
        transforms.Resize((256, 256)),
        transforms.RandomCrop((224, 224)),
        transforms.RandomHorizontalFlip(0.5),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.22, hue=0),
        transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET, interpolation=InterpolationMode.BILINEAR),
        # transforms.RandomAffine(5, translate=(0.13, 0.13), scale=(0.74, 1.32), fillcolor=(255, 255, 255), interpolation=InterpolationMode.BICUBIC),
        transforms.ToTensor(),
    ]),
    
    # the transforms for validation and testing
    'VL_AND_TE_TFMS': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ]),
}

########################################################################
"""# Prepare Label2Name & Word Embeddings"""
########################################################################
label2name_dict = dict()
with open(cfg['LABEL2NAME_PATH'], 'r') as f:
    for line in f.read().splitlines():
        num_lbl, fcr, txt_lbl = line.strip().split(' ')
        label2name_dict[int(num_lbl)] = {'fcr': fcr, 'name': txt_lbl}


if not os.path.exists('./cc.zh.300.bin'):
    fasttext.util.download_model('zh', if_exists='ignore')
ft = fasttext.load_model('cc.zh.300.bin')

def _calc_cos_sim(vec_1, vec_2, eps=1e-25):
    return (np.dot(vec_1, vec_2) + eps) / ((np.linalg.norm(vec_1) * np.linalg.norm(vec_2)) + eps)

def _calc_words_sim(word_1, word_2):
    sim_12 = np.mean([np.max([_calc_cos_sim(ft[ch_1], ft[ch_2]) for ch_2 in word_2]) for ch_1 in word_1])
    sim_21 = np.mean([np.max([_calc_cos_sim(ft[ch_1], ft[ch_2]) for ch_1 in word_1]) for ch_2 in word_2])
    weighting_ratio = len(word_1) / (len(word_1) + len(word_2))
    sim = weighting_ratio * sim_12 + (1. - weighting_ratio) * sim_21
    return sim

# give it a try
for num_lbl_1 in range(cfg['N_CLS']):
    name_1 = label2name_dict[num_lbl_1]['name']
    if '飯' in name_1:
    # if '蝦' in name_1:
    # if '湯' in name_1:
        calculated = []
        for num_lbl_2 in range(cfg['N_CLS']):
            name_2 = label2name_dict[num_lbl_2]['name']
            sim = _calc_words_sim(name_1, name_2)
            calculated.append((sim, name_1, name_2, num_lbl_1, num_lbl_2))
        
        calculated = sorted(calculated, key=lambda x: x[0])
        buxiang, xiang = [], []
        for sim, name_1, name_2, _num_lbl_1, _num_lbl_2 in calculated:
            # print(f'| {name_1}[{_num_lbl_1}] | {name_2}[{_num_lbl_2}] | {sim:.4f} |')
            if sim < .3:
                buxiang.append(_num_lbl_2)
            if sim > .8:
                xiang.append(_num_lbl_2)
        break

########################################################################
"""# Dataset and DataLoader""" # contains 1.ImbalancedDatasetSampler
########################################################################
# the customed dataset
class FoodDataset(Dataset):
    def __init__(self, tfm, split):
        assert split in ('train', 'val', 'test'), '"split" must be "train", "val", or "test"'

        self.__data_root = os.path.join(cfg['DATA_DIR'], split)
        self.__split = split
        self.__tfm = tfm

        # when testing: collect the filenames only
        self.__all_data = []
        if self.__split == 'test':
            self.__all_data.extend([img_filename for img_filename in sorted(os.listdir(self.__data_root)) if img_filename.endswith('.jpg')])
        # when training or validation: collect the file-paths and the respective labels
        else:
            for cls_idx in range(cfg['N_CLS']):
                self.__all_data.extend([
                    (os.path.join(self.__data_root, f'{cls_idx}', img_filename), cls_idx) for img_filename in os.listdir(os.path.join(self.__data_root, f'{cls_idx}')) if img_filename.endswith('.jpg')
                ])
            random.shuffle(self.__all_data)
        
        # the length of the dataset
        self.__len = len(self.__all_data)
        print(self.__split, self.__len)

    def get_labels(self):
        return  [lbl for _, lbl in self.__all_data]

    def __getitem__(self, idx):
        # when testing: return the image-id and the image
        if self.__split == 'test':
            filename = self.__all_data[idx]
            img_id = filename[:filename.rindex('.')]
            img = Image.open(os.path.join(self.__data_root, filename)).convert('RGB')
            img = self.__tfm(img)
            return img_id, img
        # when training or validation: return the image and the respective label
        else:
            file_path, lbl = self.__all_data[idx]
            img = Image.open(file_path).convert('RGB')
            img = self.__tfm(img)
            return img, lbl

    def __len__(self):
        return self.__len

# the data-loader for training
tr_dataset = FoodDataset(tfm=cfg['TR_TFMS'], split='train')
tr_loader = DataLoader(tr_dataset, batch_size=cfg['BATCH_SZ'], sampler=ImbalancedDatasetSampler(tr_dataset), num_workers=0, pin_memory=True)
# for validation
vl_dataset = FoodDataset(tfm=cfg['VL_AND_TE_TFMS'], split='val')
vl_loader = DataLoader(vl_dataset, batch_size=cfg['BATCH_SZ'], shuffle=False, num_workers=0, pin_memory=True)
# for testing
te_dataset = FoodDataset(tfm=cfg['VL_AND_TE_TFMS'], split='test')
te_loader = DataLoader(te_dataset, batch_size=cfg['BATCH_SZ'], shuffle=False, num_workers=0, pin_memory=True)

dataiter = iter(tr_loader)
images, labels = dataiter.next()
print(images.shape[2], images.shape[3])
plt.imshow(images[0].permute(1, 2, 0))
plt.show()
grid_img = torchvision.utils.make_grid(images, nrow=16)
plt.figure(figsize=(20,20))
plt.imshow(grid_img.permute(1, 2, 0))
plt.show()

label_file = open('./food_data/label2name.txt')
label_mapping = [line.split(' ')[1] for line in label_file.readlines()]

images_per_class = []
for cls_idx in range(1000):
    cls_idx = str(cls_idx)
    num_images = len(os.listdir(os.path.join('./food_data/train', cls_idx)))
    images_per_class.append(num_images)

########################################################################
"""# Build Model""" #  contains 2.ViT-pretrained-weight
########################################################################
model = timm.create_model(
    'vit_base_patch16_224',
    pretrained=True,
    img_size=224,
    num_classes=cfg['N_CLS'],
).to(cfg['DEVICE'])

print(model)

########################################################################
"""### Load Pretrained Weight""" # ABLATION: Load SSL here!
########################################################################
pretrain_path = "supervised-or-self-supervised-pretrained"
state = torch.load(pretrain_path)
model.load_state_dict(state['state_dict'])

# freeze layers except classifier layer
# for param in model.parameters():
#     param.requires_grad = False
# for param in model.head.parameters():
#     param.requires_grad = True
# model.head = nn.Sequential(
#     nn.Linear(768, 1000)
# )

model = model.to(cfg['DEVICE'])


########################################################################
"""### fasttext Loss"""
########################################################################
def _obtain_text_label_loss_term(gts):
    batch_sz = gts.shape[0]

    former_gts = gts[:batch_sz // 2]
    latter_gts = gts[batch_sz // 2:][:len(former_gts)]
    
    losses = [
        _calc_words_sim(
            label2name_dict[gt_1.item() if hasattr(gt_1, 'item') else gt_1]['name'],
            label2name_dict[gt_2.item() if hasattr(gt_2, 'item') else gt_2]['name'],
        )
        for gt_1, gt_2 in zip(former_gts, latter_gts) if gt_1 != gt_2
    ]
    return np.mean(losses)

########################################################################
"""### Label Smoothing Loss"""
########################################################################
class LabelSmoothingLoss(torch.nn.Module):
    def __init__(self, smoothing: float = 0.1, 
                 reduction="mean", weight=None):
        super(LabelSmoothingLoss, self).__init__()
        self.smoothing   = smoothing
        self.reduction = reduction
        self.weight    = weight

    def reduce_loss(self, loss):
        return loss.mean() if self.reduction == 'mean' else loss.sum() \
         if self.reduction == 'sum' else loss

    def linear_combination(self, x, y):
        return self.smoothing * x + (1 - self.smoothing) * y

    def forward(self, preds, target): # if preds: [batch_size, num_classes], target: [barch_size, num_classes]
        assert 0 <= self.smoothing < 1

        if self.weight is not None:
            self.weight = self.weight.to(preds.cfg['DEVICE'])

        n = preds.size(-1)
        log_preds = F.log_softmax(preds, dim=-1)
        loss = self.reduce_loss(-log_preds.sum(dim=-1))
        nll = F.nll_loss(
            log_preds, target, reduction=self.reduction, weight=self.weight
        )
        return self.linear_combination(loss / n, nll)

########################################################################
"""### Pairwise Confusion"""
########################################################################
def PairwiseConfusion(features, target):
    batch_size = features.size(0)
    if float(batch_size) % 2 != 0:
        return 0
    batch_left = features[:int(0.5*batch_size)]
    batch_right = features[int(0.5*batch_size):]

    target_left = target[:int(0.5*batch_size)]
    target_right = target[int(0.5*batch_size):]

    target_mask_t = torch.eq(target_left, target_right)
    target_mask = ~target_mask_t
    target_mask = target_mask.type(torch.cuda.FloatTensor)
    number = target_mask.sum()
    loss  = (torch.norm((batch_left - batch_right).abs(),2, 1) * target_mask).sum() / number

    return loss

###################################################################################################
"""### Re-Weighting: LDAM
reference: https://github.com/kaidic/LDAM-DRW/blob/master/cifar_train.py 
"""
###################################################################################################
def focal_loss(input_values, gamma):
    """Computes the focal loss"""
    p = torch.exp(-input_values)
    loss = (1 - p) ** gamma * input_values
    return loss.mean()

class FocalLoss(nn.Module):
    def __init__(self, weight=None, gamma=0.):
        super(FocalLoss, self).__init__()
        assert gamma >= 0
        self.gamma = gamma
        self.weight = weight

    def forward(self, input, target):
        return focal_loss(F.cross_entropy(input, target, reduction='none', weight=self.weight), self.gamma)

class LDAMLoss(nn.Module):
    
    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):
        super(LDAMLoss, self).__init__()
        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))
        m_list = m_list * (max_m / np.max(m_list))
        m_list = torch.cuda.FloatTensor(m_list)
        self.m_list = m_list
        assert s > 0
        self.s = s

        self.weight = weight

    def forward(self, x, target):
        index = torch.zeros_like(x, dtype=torch.uint8)
        index.scatter_(1, target.data.view(-1, 1), 1)
        
        index_float = index.type(torch.cuda.FloatTensor)
        # print(self.m_list.shape)
        # print(index_float.shape)
        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))
        batch_m = batch_m.view((-1, 1))
        x_m = x - batch_m
    
        output = torch.where(index, x_m, x)
        return F.cross_entropy(self.s*output, target, weight=self.weight)


###################################################################################################
"""### Mix Up augmentation and its loss
Reference: https://github.com/hongyi-zhang/mixup/blob/master/cifar/utils.py
"""
###################################################################################################
def mixup_data(x, y, alpha=1.0, use_cuda=True):

    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''
    if alpha > 0.:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1.
    batch_size = x.size()[0]
    if use_cuda: # 隨機打亂順序
        index = torch.randperm(batch_size).cuda()
    else:
        index = torch.randperm(batch_size)

    mixed_x = lam * x + (1 - lam) * x[index,:] # w * a + (1-w) * b
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam # 混合型資料, 原始順序，打亂的順序, 權重

def mixup_criterion(y_a, y_b, lam):
    return lambda criterion, pred: lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b) # 權重*偏左loss + (1-權重)*偏右loss

###################################################################################################
"""### Learning Rate Scheduler"""
###################################################################################################
def get_cosine_schedule_with_warmup(
    optimizer: Optimizer, num_warmup_steps: int, num_training_steps: int, num_cycles: float = 0.5, last_epoch: int = -1
):
    """
    Create a schedule with a learning rate that decreases following the values of the cosine function between the
    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the
    initial lr set in the optimizer.

    Args:
        optimizer (:class:`~torch.optim.Optimizer`):
            The optimizer for which to schedule the learning rate.
        num_warmup_steps (:obj:`int`):
            The number of steps for the warmup phase.
        num_training_steps (:obj:`int`):
            The total number of training steps.
        num_cycles (:obj:`float`, `optional`, defaults to 0.5):
            The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0
            following a half-cosine).
        last_epoch (:obj:`int`, `optional`, defaults to -1):
            The index of the last epoch when resuming training.

    Return:
        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.
    """

    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))

    return LambdaLR(optimizer, lr_lambda, last_epoch)

###################################################################################################
"""## VI. Define Config"""
###################################################################################################
label_file = open(cfg['LABEL2NAME_PATH'])
label_mapping = [line.split(' ')[1] for line in label_file.readlines()]

def count_acc_category(acc_list):
    c_accs, f_accs, r_accs = [], [], []
    for label, acc in acc_list:
        if label_mapping[label] == 'c':
            c_accs.append(acc)
        elif label_mapping[label] == 'f':
            f_accs.append(acc)
        elif label_mapping[label] == 'r':
            r_accs.append(acc)
    return np.array(c_accs).mean(), np.array(f_accs).mean(), np.array(r_accs).mean()

num_epochs = 12
save_per_iters = 500
print_log_per_iters = 100
output_path = "./checkpoints" 

# ABLATION: switch to CrossEntropyLoss
#criterion = nn.CrossEntropyLoss().to(cfg['DEVICE']EVICE'])
smoothing = 0.1
criterion = LabelSmoothingLoss(smoothing=smoothing).to(cfg['DEVICE'])

origin_lr=1e-5
weight_decay=1e-6
optimizer = torch.optim.Adam(model.parameters(), lr=origin_lr, weight_decay=weight_decay)

factor = 0.9
patience = 1
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience)

start_epoch = 0
iters = 0

best_valid_accu = 0.0
best_valid_freq = 0.0
best_valid_comm = 0.0
best_valid_rare = 0.0

Train_Loss_Iter = []
Train_Accu_Iter = []

Valid_Loss_Iter = []
Valid_Accu_Iter = []

Valid_Freq_Iter = []
Valid_Comm_Iter = []
Valid_Rare_Iter = []

Valid_Loss_Epoch = []
Valid_Accu_Epoch = []

Valid_Freq_Epoch = []
Valid_Comm_Epoch = []
Valid_Rare_Epoch = []

#################################################################
##### Resume Training When Interrupted stop suddenly 
#################################################################
resume = False
if resume:
    PATH = os.path.join(output_path, "model_last.pt")
    state = torch.load(PATH)
    model.load_state_dict(state["state_dict"])
    optimizer.load_state_dict(state["optimizer"])
    scheduler.load_state_dict(state["scheduler"])
    start_epoch = state["epoch"] - 1 
    iters = state["iters"] 

    # need to save it otherwise we cannot check which one surpass past record
    best_valid_accu = state["best_valid_accu"]
    best_valid_freq = state['best_valid_freq']
    best_valid_comm = state['best_valid_comm']
    best_valid_rare = state['best_valid_rare']
    
    Train_Loss_Iter = state['Train_Loss_Iter']
    Train_Accu_Iter = state['Train_Accu_Iter']

    Valid_Loss_Iter = state['Valid_Loss_Iter']
    Valid_Accu_Iter = state['Valid_Accu_Iter']

    Valid_Freq_Iter = state['Valid_Freq_Iter']
    Valid_Comm_Iter = state['Valid_Comm_Iter']
    Valid_Rare_Iter = state['Valid_Rare_Iter']

    Valid_Loss_Epoch = state['Valid_Loss_Epoch']
    Valid_Accu_Epoch = state['Valid_Accu_Epoch']

    Valid_Freq_Epoch = state['Valid_Freq_Epoch']
    Valid_Comm_Epoch = state['Valid_Comm_Epoch']
    Valid_Rare_Epoch = state['Valid_Rare_Epoch']

###################################################################################################
"""## VII. Training Loop"""
###################################################################################################
model.train()

for epoch in range(start_epoch, num_epochs):

    # end = time.time()
    for i, (images, target) in enumerate(tr_loader):
        # switch to train mode 
        model.train()
        # measure data loading time
        # data_time.update(time.time() - end)
        images = images.to(cfg['DEVICE'])
        target = target.to(cfg['DEVICE'])

        # compute output
        output = model(images)

        # re-weighting LDAM Loss
          # 法1
        # idx = epoch // 160
        # betas = [0, 0.9999]
        # effective_num = 1.0 - np.power(betas[idx], cls_num_list)
        # per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)
        # per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(cls_num_list)
        # per_cls_weights = torch.FloatTensor(per_cls_weights).to(device)

          # 法2
        beta = 0.9999
        effective_num = 1.0 - np.power(beta, images_per_class)
        per_cls_weights = (1.0 - beta) / np.array(effective_num)
        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(images_per_class)
        per_cls_weights = torch.FloatTensor(per_cls_weights).to(cfg['DEVICE'])
        criterion_ldam = LDAMLoss(cls_num_list=images_per_class, max_m=0.5, s=30, weight=per_cls_weights).to(cfg['DEVICE'])

        ####################################################################################################
        ###### LabelSmooth/CELoss + FastText + LDAM (ABLATION: turn on or turn off fasttext and LDAM)
        ####################################################################################################
        loss = criterion(output, target) + 1.0 * _obtain_text_label_loss_term(target) + 0.5 * criterion_ldam(output, target)
        acc = 100.0 * (output.argmax(dim=-1) == target).float().mean()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        ####################################################################################################
        ##### mix up augmentation (這是新的資料了，因此共有兩份資料，原始output以及augmented output) (ABLATION: turn on or turn off mix up)
        ####################################################################################################
        inputs, targets_a, targets_b, lam = mixup_data(images, target, alpha=1.0, use_cuda=True)
        inputs, targets_a, targets_b = Variable(inputs), Variable(targets_a), Variable(targets_b)
        outputs = model(inputs)

        loss_func = mixup_criterion(targets_a, targets_b, lam)
        loss = loss_func(criterion, outputs) # 此時似乎沒辦法對rare class(已經mix) 以及 similar class(已經mix) 算loss

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        ####################################################################################################
        ##### Print and Record Train Log per 100 iters
        ####################################################################################################
        Train_Loss_Iter.append(loss.data.cpu().numpy())
        Train_Accu_Iter.append(acc.data.cpu().numpy())
        
        # 為了避免log太多被截掉
        if (iters+1) % print_log_per_iters == 0:
            current_lr = optimizer.param_groups[0]["lr"]
            # print ('epoch: %d, iters: %d, train_accu: %.4f, train_loss: %.4f, lr: %.8f' % (epoch+1, iters+1, acc, loss, current_lr))
            print(f'====== | [TR] | EP = {epoch + 1:03d}/{num_epochs:03d} | ITER = {iters + 1:04d} | LOSS = {loss:.4f} | ACC = {acc:.4f} | LR = {current_lr:.8f} | ======')

        if (iters+1) % save_per_iters == 0:
            
            ####################################################################################################
            # I. Calculate Valid Accu/Loss
            ####################################################################################################
            valid_loss = 0
            correct = 0
            valid_accu = 0
            predictions = []
            vl_category_list = []
            # switch to evaluate mode
            model.eval()
            with torch.no_grad():
                for i, (images, target) in enumerate(vl_loader):
                    images = images.to(cfg['DEVICE'])
                    target = target.to(cfg['DEVICE'])

                    # compute output
                    output = model(images)
                    loss = criterion(output, target)

                    # self-measurement
                    valid_loss += criterion(output, target).item() # sum up batch loss
                    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability
                    correct += pred.eq(target.view_as(pred)).sum().item()
                    predictions.extend(output.argmax(dim=-1).cpu().numpy().tolist())

                    vl_category_list += [(target[i].item(), (output.argmax(dim=-1) == target)[i].float().item()) for i in range(output.shape[0])]

                ####################################################################################################
                ##### II. Print and Record Valid Log, Update LR-SCHEDULE
                ####################################################################################################
                valid_loss /= len(vl_loader.dataset)
                valid_accu = 100. * correct / len(vl_loader.dataset)
                c_acc, f_acc, r_acc = count_acc_category(vl_category_list)
                print(f'\t\t====== | [VL] | EP = {epoch + 1:03d}/{num_epochs:03d} | ITER = {iters + 1:04d} | LOSS = {valid_loss:.4f} | ACC = {valid_accu:.4f} | ======')
                print(f'\t\t====== | [VL] | FREQ-ACC = {f_acc:.4f} | COMM-ACC = {c_acc:.4f} | RARE-ACC = {r_acc:.4f} | ======')

                Valid_Loss_Iter.append(valid_loss)
                Valid_Accu_Iter.append(valid_accu)

                Valid_Freq_Iter.append(f_acc)
                Valid_Comm_Iter.append(c_acc)
                Valid_Rare_Iter.append(r_acc)

                scheduler.step(valid_loss)

                #######################################################################################################################
                ##### III. save Iter_model | model_best_main | model_best_freq | model_best_comm | model_best_rare | model_last
                #######################################################################################################################
                # for example: Iter3000_model_m_0.6623_f_0.8765_c_0.6125_r_0.1875.pt
                model_path = ("Iter%d_model_m_%.4f_f_%.4f_c_%.4f_r_%.4f.pt" % (iters+1, valid_accu, f_acc, c_acc, r_acc))
                torch.save({
                    'epoch': epoch + 1,
                    'iters': iters + 1,
                    'state_dict': model.state_dict(),
                    'best_valid_accu': best_valid_accu,
                    'valid_accu': valid_accu,
                    'f_acc': f_acc,
                    'c_acc': c_acc,
                    'r_acc': r_acc,
                }, os.path.join(output_path, model_path))

                # III. save model best main
                if valid_accu > best_valid_accu:
                    best_valid_accu = valid_accu
                    print("Save Best Valid Accu")
                    model_path = "model_best.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))
                
                # III. save model best freq
                if f_acc > best_valid_freq:
                    best_valid_freq = f_acc
                    print("Save Best Valid Freq")
                    model_path = "model_best_freq.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))

                # III. save model best comm
                if c_acc > best_valid_comm:
                    best_valid_comm = c_acc
                    print("Save Best Valid Comm")
                    model_path = "model_best_comm.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))

                # III. save model best rare
                if r_acc > best_valid_rare:
                    best_valid_rare = r_acc
                    print("Save Best Valid Rare")
                    model_path = "model_best_rare.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))

                # III. save model last
                model_path = "model_last.pt"
                torch.save({
                    'epoch': epoch + 1,
                    'iters': iters + 1,
                    'state_dict': model.state_dict(),
                    'best_valid_accu': best_valid_accu,
                    'optimizer' : optimizer.state_dict(),
                    'scheduler' : scheduler.state_dict(),

                    'valid_accu': valid_accu,
                    'f_acc': f_acc,
                    'c_acc': c_acc,
                    'r_acc': r_acc,

                    'best_valid_freq': best_valid_freq,
                    'best_valid_comm': best_valid_comm,
                    'best_valid_rare': best_valid_rare,

                    'Train_Loss_Iter': Train_Loss_Iter,
                    'Train_Accu_Iter': Train_Accu_Iter,

                    'Valid_Loss_Iter': Valid_Loss_Iter,
                    'Valid_Accu_Iter': Valid_Accu_Iter,

                    'Valid_Freq_Iter': Valid_Freq_Iter,
                    'Valid_Comm_Iter': Valid_Comm_Iter,
                    'Valid_Rare_Iter': Valid_Rare_Iter,

                    'Valid_Loss_Epoch': Valid_Loss_Epoch,
                    'Valid_Accu_Epoch': Valid_Accu_Epoch,

                    'Valid_Freq_Epoch': Valid_Freq_Epoch,
                    'Valid_Comm_Epoch': Valid_Comm_Epoch,
                    'Valid_Rare_Epoch': Valid_Rare_Epoch,

                }, os.path.join(output_path, model_path))
        iters = iters + 1

    ####################################################################################################
    ##### Epochwise evaluate on validation set 
    ####################################################################################################
    valid_loss = 0
    correct = 0
    valid_accu = 0
    predictions = []
    vl_category_list = []
    # switch to evaluate mode
    model.eval()
    with torch.no_grad():
        for i, (images, target) in enumerate(vl_loader):
            images = images.to(cfg['DEVICE'])
            target = target.to(cfg['DEVICE'])

            # compute output
            output = model(images)
            loss = criterion(output, target)

            # self-measurement
            valid_loss += criterion(output, target).item() # sum up batch loss
            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()
            predictions.extend(output.argmax(dim=-1).cpu().numpy().tolist())

            vl_category_list += [(target[i].item(), (output.argmax(dim=-1) == target)[i].float().item()) for i in range(output.shape[0])]

        ####################################################################################################
        ##### II. Print and Record Valid Log
        ####################################################################################################
        valid_loss /= len(vl_loader.dataset)
        valid_accu = 100. * correct / len(vl_loader.dataset)
        c_acc, f_acc, r_acc = count_acc_category(vl_category_list)
        print(f'\t\t====== | [VL] | EP = {epoch + 1:03d}/{num_epochs:03d} | ITER = {iters + 1:04d} | LOSS = {valid_loss:.4f} | ACC = {valid_accu:.4f} | ======')
        print(f'\t\t====== | [VL] | FREQ-ACC = {f_acc:.4f} | COMM-ACC = {c_acc:.4f} | RARE-ACC = {r_acc:.4f} | ======')
        
        Valid_Loss_Epoch.append(valid_loss)
        Valid_Accu_Epoch.append(valid_accu)

        Valid_Freq_Epoch.append(f_acc)
        Valid_Comm_Epoch.append(c_acc)
        Valid_Rare_Epoch.append(r_acc)

        ####################################################################################################
        ##### III. save Epoch_model | model_best_main | model_last
        ####################################################################################################
        model_path = ("Epoch%d_model_m_%.4f_f_%.4f_c_%.4f_r_%.4f.pt" % (epoch+1, valid_accu, f_acc, c_acc, r_acc))
        torch.save({
            'epoch': epoch + 1,
            'iters': iters + 1,
            'state_dict': model.state_dict(),
            'best_valid_accu': best_valid_accu,

            'valid_accu': valid_accu,
            'f_acc': f_acc,
            'c_acc': c_acc,
            'r_acc': r_acc,
            #'optimizer' : optimizer.state_dict(),
        }, os.path.join(output_path, model_path))

        if valid_accu > best_valid_accu:
            best_valid_accu = valid_accu
            print("Save Best Valid Accu")
            model_path = "model_best.pt"
            torch.save({
                'epoch': epoch + 1,
                'iters': iters + 1,
                'state_dict': model.state_dict(),
                'best_valid_accu': best_valid_accu,

                'valid_accu': valid_accu,
                'f_acc': f_acc,
                'c_acc': c_acc,
                'r_acc': r_acc,
            }, os.path.join(output_path, model_path))

        model_path = "model_last.pt"
        torch.save({
            'epoch': epoch + 1,
            'iters': iters + 1,
            'state_dict': model.state_dict(),
            'best_valid_accu': best_valid_accu,
            'optimizer' : optimizer.state_dict(),
            'scheduler' : scheduler.state_dict(),

            'valid_accu': valid_accu,
            'f_acc': f_acc,
            'c_acc': c_acc,
            'r_acc': r_acc,

            'best_valid_freq': best_valid_freq,
            'best_valid_comm': best_valid_comm,
            'best_valid_rare': best_valid_rare,

            'Train_Loss_Iter': Train_Loss_Iter,
            'Train_Accu_Iter': Train_Accu_Iter,

            'Valid_Loss_Iter': Valid_Loss_Iter,
            'Valid_Accu_Iter': Valid_Accu_Iter,

            'Valid_Freq_Iter': Valid_Freq_Iter,
            'Valid_Comm_Iter': Valid_Comm_Iter,
            'Valid_Rare_Iter': Valid_Rare_Iter,

            'Valid_Loss_Epoch': Valid_Loss_Epoch,
            'Valid_Accu_Epoch': Valid_Accu_Epoch,

            'Valid_Freq_Epoch': Valid_Freq_Epoch,
            'Valid_Comm_Epoch': Valid_Comm_Epoch,
            'Valid_Rare_Epoch': Valid_Rare_Epoch,

        }, os.path.join(output_path, model_path))