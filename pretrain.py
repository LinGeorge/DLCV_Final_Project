"""
vit_fasttext.ipynb

Automatically generated by Colaboratory.

共有四個位置有"ABLATION" TAG
1. pretrained weight(supervised or SSL) 路徑修改/整段註解
2. CrossEntropy or LabelSmoothing 二選一
3. LabelSmooth/CELoss + FastText + LDAM 註解掉沒用到的損失函數
4. MixUp 選擇註解/不註解

"""

########################################################################
"""# Import Packages"""
########################################################################
import os
import sys
import random
import shutil
import time
import warnings
import PIL
import math
import csv
from typing import Callable, Iterable, Optional, Tuple, Union

from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib import cm
from sklearn.manifold import TSNE
import numpy as np

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.nn.functional as F
import torch.backends.cudnn as cudnn

import torch.distributed as dist
import torch.optim
import torch.multiprocessing as mp

import torch.optim as optim
from torch.optim import Optimizer
from torch.optim.lr_scheduler import LambdaLR
import torch.utils.data
import torch.utils.data.distributed
from torch.utils.data import Dataset, DataLoader

import torchvision
import torchvision.models as models
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torchvision.transforms.transforms import InterpolationMode
from torchvision.datasets import DatasetFolder
from torchvision import models
import torchvision.utils as vutils

from torch.autograd import Variable
from torch.autograd import Function

#!pip install timm
import timm

########################################################################
"""# Fix Seeds"""
########################################################################
# fix random seeds
def fix_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    print('Seeds are now fixed.')

fix_seeds(0)

########################################################################
"""# Configurations""" # Contain 3.Auto Augmentation
########################################################################
# the configuration dictionary for p1
cfg = {
    # the cfg['DEVICE'] to be used for training and validation
    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',
    
    # the prefix for avoiding overwriting when backuping the checkpoint and output csv-files
    'BACKUP_PREFIX': 'nowd',
    
    # the number of classes
    'N_CLS': 1000,

    # the batch-size
    'BATCH_SZ': 16,
    
    # the number of epochs during training
    'N_EPOCHS': 10,

    # the name of the pretrained model under torchvision to be used
    'PRETRAINED_MODEL_NAME': 'resnet50',
    
    # the name of the optimizer used in training
    'OPTIM_NAME': 'Adam',
    
    # some parameters of the used optimizer
    'OPTIM_PARAMS': {
        'lr': 0.00005,
        # 'weight_decay': 1e-3,
    },
    
    # to determine whether to use lr-scheduler or not
    'USE_SCHED': True,
    
    # the name of the lr-scheduler used in training
    'SCHED_NAME': 'ReduceLROnPlateau',

    # the max-norm used in gradients clipping
    'MAX_NORM': 1,
    
    # some parameters of the used lr-scheduler
    'SCHED_PARAMS': {
        'factor': 0.5,
        'patience': 1,
        'min_lr': 1e-8,
    },
    
    # the directory of all data, including training, validation, and testing data
    'DATA_DIR': './food_data/',

    # the path to label2name.txt
    'LABEL2NAME_PATH': './food_data/label2name.txt',
    
    # the filename of the output csv-file
    'OUTPUT_CSV_FILENAME': 'submission.csv',
    
    # the file-paths of all four sample submission csv-files
    'SAMPLE_SUBMISSION_FILEPATHS': {
        'main': './food_data/testcase/sample_submission_main_track.csv',
        'freq': './food_data/testcase/sample_submission_freq_track.csv',
        'comm': './food_data/testcase/sample_submission_comm_track.csv',
        'rare': './food_data/testcase/sample_submission_rare_track.csv',
    },
    
    # the directory of the saved models
    'MODEL_SAVE_DIR': './saved_models',
    
    # the path of the pretrained word embedding model
    # 'PRETRAINED_WORD_EMBEDDING_MODEL_PATH': './y_360W_cbow_2D_300dim_2020v1.bin',
    'PRETRAINED_WORD_EMBEDDING_MODEL_PATH': './tmunlp_1.6B_WB_300dim_2020v1.bin',
    
    # the transforms for training (data augmentation)
    'TR_TFMS': transforms.Compose([
        # transforms.ToPILImage(),
        transforms.RandomRotation(20),
        transforms.Resize((256, 256)),
        transforms.RandomCrop((224, 224)),
        transforms.RandomHorizontalFlip(0.5),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.22, hue=0),
        transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET, interpolation=InterpolationMode.BILINEAR),
        # transforms.RandomAffine(5, translate=(0.13, 0.13), scale=(0.74, 1.32), fillcolor=(255, 255, 255), interpolation=InterpolationMode.BICUBIC),
        transforms.ToTensor(),
    ]),
    
    # the transforms for validation and testing
    'VL_AND_TE_TFMS': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ]),
}

IMG_SIZE = 224
rotate_rate = 30
center_crop = 400
crop_size = 256

train_tfm = transforms.Compose([
    # Resize the image into a fixed shape (height = width = 128)
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(rotate_rate),
    transforms.CenterCrop((center_crop, center_crop)),
    transforms.RandomCrop(crop_size),
    transforms.ColorJitter(brightness=(0.8, 1.6),contrast=(0.8, 1.6),saturation=0.22),
    #transforms.RandomAffine(5, translate=(0.13, 0.13), scale=(0.74, 1.32), fillcolor=(255, 255, 255), interpolation=transforms.functional.InterpolationMode.BICUBIC),
           
    transforms.Resize((IMG_SIZE, IMG_SIZE)),

    # ToTensor() should be the last one of the transforms.
    transforms.ToTensor(),
    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# We don't need augmentations in testing and validation.
# All we need here is to resize the PIL image and transform it into Tensor.
test_tfm = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
])

########################################################################
"""# Dataset and DataLoader""" # contains 1.ImbalancedDatasetSampler
########################################################################
# the customed dataset
class FoodDataset(Dataset):
    def __init__(self, tfm, split):
        assert split in ('train', 'val', 'test'), '"split" must be "train", "val", or "test"'

        self.__data_root = os.path.join(cfg['DATA_DIR'], split)
        self.__split = split
        self.__tfm = tfm

        # when testing: collect the filenames only
        self.__all_data = []
        if self.__split == 'test':
            self.__all_data.extend([img_filename for img_filename in sorted(os.listdir(self.__data_root)) if img_filename.endswith('.jpg')])
        # when training or validation: collect the file-paths and the respective labels
        else:
            for cls_idx in range(cfg['N_CLS']):
                self.__all_data.extend([
                    (os.path.join(self.__data_root, f'{cls_idx}', img_filename), cls_idx) for img_filename in os.listdir(os.path.join(self.__data_root, f'{cls_idx}')) if img_filename.endswith('.jpg')
                ])
            random.shuffle(self.__all_data)
        
        # the length of the dataset
        self.__len = len(self.__all_data)
        print(self.__split, self.__len)

    def get_labels(self):
        return  [lbl for _, lbl in self.__all_data]

    def __getitem__(self, idx):
        # when testing: return the image-id and the image
        if self.__split == 'test':
            filename = self.__all_data[idx]
            img_id = filename[:filename.rindex('.')]
            img = Image.open(os.path.join(self.__data_root, filename)).convert('RGB')
            img = self.__tfm(img)
            return img_id, img
        # when training or validation: return the image and the respective label
        else:
            file_path, lbl = self.__all_data[idx]
            img = Image.open(file_path).convert('RGB')
            img = self.__tfm(img)
            return img, lbl

    def __len__(self):
        return self.__len

batch_size = 16 # from 128 to 512
# the data-loader for training
tr_dataset = FoodDataset(tfm=train_tfm, split='train')
tr_loader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)
# for validation
vl_dataset = FoodDataset(tfm=test_tfm, split='val')
vl_loader = DataLoader(vl_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)
# for testing
te_dataset = FoodDataset(tfm=test_tfm, split='test')
te_loader = DataLoader(te_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)

dataiter = iter(tr_loader)
images, labels = dataiter.next()
print(images.shape[2], images.shape[3])
plt.imshow(images[0].permute(1, 2, 0))
plt.show()
grid_img = torchvision.utils.make_grid(images, nrow=16)
plt.figure(figsize=(20,20))
plt.imshow(grid_img.permute(1, 2, 0))
plt.show()


########################################################################
"""# Build Model""" #  contains 2.ViT-pretrained-weight
########################################################################
model = timm.create_model(
    'vit_base_patch16_224',
    pretrained=True,
    img_size=IMG_SIZE,
    num_classes=cfg['N_CLS'],
).to(cfg['DEVICE'])

print(model)

########################################################################
"""### Label Smoothing Loss"""
########################################################################
class LabelSmoothingLoss(torch.nn.Module):
    def __init__(self, smoothing: float = 0.1, 
                 reduction="mean", weight=None):
        super(LabelSmoothingLoss, self).__init__()
        self.smoothing   = smoothing
        self.reduction = reduction
        self.weight    = weight

    def reduce_loss(self, loss):
        return loss.mean() if self.reduction == 'mean' else loss.sum() \
         if self.reduction == 'sum' else loss

    def linear_combination(self, x, y):
        return self.smoothing * x + (1 - self.smoothing) * y

    def forward(self, preds, target): # if preds: [batch_size, num_classes], target: [barch_size, num_classes]
        assert 0 <= self.smoothing < 1

        if self.weight is not None:
            self.weight = self.weight.to(preds.cfg['DEVICE'])

        n = preds.size(-1)
        log_preds = F.log_softmax(preds, dim=-1)
        loss = self.reduce_loss(-log_preds.sum(dim=-1))
        nll = F.nll_loss(
            log_preds, target, reduction=self.reduction, weight=self.weight
        )
        return self.linear_combination(loss / n, nll)

###################################################################################################
"""### Learning Rate Scheduler"""
###################################################################################################
def get_cosine_schedule_with_warmup(
    optimizer: Optimizer, num_warmup_steps: int, num_training_steps: int, num_cycles: float = 0.5, last_epoch: int = -1
):
    """
    Create a schedule with a learning rate that decreases following the values of the cosine function between the
    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the
    initial lr set in the optimizer.

    Args:
        optimizer (:class:`~torch.optim.Optimizer`):
            The optimizer for which to schedule the learning rate.
        num_warmup_steps (:obj:`int`):
            The number of steps for the warmup phase.
        num_training_steps (:obj:`int`):
            The total number of training steps.
        num_cycles (:obj:`float`, `optional`, defaults to 0.5):
            The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0
            following a half-cosine).
        last_epoch (:obj:`int`, `optional`, defaults to -1):
            The index of the last epoch when resuming training.

    Return:
        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.
    """

    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))

    return LambdaLR(optimizer, lr_lambda, last_epoch)

###################################################################################################
"""## VI. Define Config"""
###################################################################################################
label_file = open(cfg['LABEL2NAME_PATH'])
label_mapping = [line.split(' ')[1] for line in label_file.readlines()]

def count_acc_category(acc_list):
    c_accs, f_accs, r_accs = [], [], []
    for label, acc in acc_list:
        if label_mapping[label] == 'c':
            c_accs.append(acc)
        elif label_mapping[label] == 'f':
            f_accs.append(acc)
        elif label_mapping[label] == 'r':
            r_accs.append(acc)
    return np.array(c_accs).mean(), np.array(f_accs).mean(), np.array(r_accs).mean()

num_epochs = 12
save_per_iters = 500
print_log_per_iters = 100
output_path = "./pretrain" 
if not os.path.exists(output_path):
    os.makedirs(output_path)
    print("create output_dir: ", output_path)

# ABLATION: switch to CrossEntropyLoss
criterion = nn.CrossEntropyLoss().to(cfg['DEVICE'])
# smoothing = 0.1
# criterion = LabelSmoothingLoss(smoothing=smoothing).to(cfg['DEVICE'])

origin_lr=1e-5
weight_decay=1e-6
optimizer = torch.optim.Adam(model.parameters(), lr=origin_lr, weight_decay=weight_decay)

factor = 0.9
patience = 1
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience)

start_epoch = 0
iters = 0

best_valid_accu = 0.0
best_valid_freq = 0.0
best_valid_comm = 0.0
best_valid_rare = 0.0

Train_Loss_Iter = []
Train_Accu_Iter = []

Valid_Loss_Iter = []
Valid_Accu_Iter = []

Valid_Freq_Iter = []
Valid_Comm_Iter = []
Valid_Rare_Iter = []

Valid_Loss_Epoch = []
Valid_Accu_Epoch = []

Valid_Freq_Epoch = []
Valid_Comm_Epoch = []
Valid_Rare_Epoch = []

#################################################################
##### Resume Training When Interrupted stop suddenly 
#################################################################
resume = False
if resume:
    PATH = os.path.join(output_path, "model_last.pt")
    state = torch.load(PATH)
    model.load_state_dict(state["state_dict"])
    optimizer.load_state_dict(state["optimizer"])
    scheduler.load_state_dict(state["scheduler"])
    start_epoch = state["epoch"] - 1 
    iters = state["iters"] 

    # need to save it otherwise we cannot check which one surpass past record
    best_valid_accu = state["best_valid_accu"]
    best_valid_freq = state['best_valid_freq']
    best_valid_comm = state['best_valid_comm']
    best_valid_rare = state['best_valid_rare']
    
    Train_Loss_Iter = state['Train_Loss_Iter']
    Train_Accu_Iter = state['Train_Accu_Iter']

    Valid_Loss_Iter = state['Valid_Loss_Iter']
    Valid_Accu_Iter = state['Valid_Accu_Iter']

    Valid_Freq_Iter = state['Valid_Freq_Iter']
    Valid_Comm_Iter = state['Valid_Comm_Iter']
    Valid_Rare_Iter = state['Valid_Rare_Iter']

    Valid_Loss_Epoch = state['Valid_Loss_Epoch']
    Valid_Accu_Epoch = state['Valid_Accu_Epoch']

    Valid_Freq_Epoch = state['Valid_Freq_Epoch']
    Valid_Comm_Epoch = state['Valid_Comm_Epoch']
    Valid_Rare_Epoch = state['Valid_Rare_Epoch']

###################################################################################################
"""## VII. Training Loop"""
###################################################################################################
model.train()

for epoch in range(start_epoch, num_epochs):

    # end = time.time()
    for i, (images, target) in enumerate(tr_loader):
        # switch to train mode 
        model.train()
        # measure data loading time
        # data_time.update(time.time() - end)
        images = images.to(cfg['DEVICE'])
        target = target.to(cfg['DEVICE'])

        # compute output
        output = model(images)
        loss = criterion(output, target)
        acc = 100.0 * (output.argmax(dim=-1) == target).float().mean()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        ####################################################################################################
        ##### Print and Record Train Log per 100 iters
        ####################################################################################################
        Train_Loss_Iter.append(loss.data.cpu().numpy())
        Train_Accu_Iter.append(acc.data.cpu().numpy())
        
        # 為了避免log太多被截掉
        if (iters+1) % print_log_per_iters == 0:
            current_lr = optimizer.param_groups[0]["lr"]
            # print ('epoch: %d, iters: %d, train_accu: %.4f, train_loss: %.4f, lr: %.8f' % (epoch+1, iters+1, acc, loss, current_lr))
            print(f'====== | [TR] | EP = {epoch + 1:03d}/{num_epochs:03d} | ITER = {iters + 1:04d} | LOSS = {loss:.4f} | ACC = {acc:.4f} | LR = {current_lr:.8f} | ======')

        if (iters+1) % save_per_iters == 0:
            
            ####################################################################################################
            # I. Calculate Valid Accu/Loss
            ####################################################################################################
            valid_loss = 0
            correct = 0
            valid_accu = 0
            predictions = []
            vl_category_list = []
            # switch to evaluate mode
            model.eval()
            with torch.no_grad():
                for i, (images, target) in enumerate(vl_loader):
                    images = images.to(cfg['DEVICE'])
                    target = target.to(cfg['DEVICE'])

                    # compute output
                    output = model(images)
                    loss = criterion(output, target)

                    # self-measurement
                    valid_loss += criterion(output, target).item() # sum up batch loss
                    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability
                    correct += pred.eq(target.view_as(pred)).sum().item()
                    predictions.extend(output.argmax(dim=-1).cpu().numpy().tolist())

                    vl_category_list += [(target[i].item(), (output.argmax(dim=-1) == target)[i].float().item()) for i in range(output.shape[0])]

                ####################################################################################################
                ##### II. Print and Record Valid Log, Update LR-SCHEDULE
                ####################################################################################################
                valid_loss /= len(vl_loader.dataset)
                valid_accu = 100. * correct / len(vl_loader.dataset)
                c_acc, f_acc, r_acc = count_acc_category(vl_category_list)
                print(f'\t\t====== | [VL] | EP = {epoch + 1:03d}/{num_epochs:03d} | ITER = {iters + 1:04d} | LOSS = {valid_loss:.4f} | ACC = {valid_accu:.4f} | ======')
                print(f'\t\t====== | [VL] | FREQ-ACC = {f_acc:.4f} | COMM-ACC = {c_acc:.4f} | RARE-ACC = {r_acc:.4f} | ======')

                Valid_Loss_Iter.append(valid_loss)
                Valid_Accu_Iter.append(valid_accu)

                Valid_Freq_Iter.append(f_acc)
                Valid_Comm_Iter.append(c_acc)
                Valid_Rare_Iter.append(r_acc)

                scheduler.step(valid_loss)

                #######################################################################################################################
                ##### III. save Iter_model | model_best_main | model_best_freq | model_best_comm | model_best_rare | model_last
                #######################################################################################################################
                # for example: Iter3000_model_m_0.6623_f_0.8765_c_0.6125_r_0.1875.pt
                model_path = ("Iter%d_model_m_%.4f_f_%.4f_c_%.4f_r_%.4f.pt" % (iters+1, valid_accu, f_acc, c_acc, r_acc))
                torch.save({
                    'epoch': epoch + 1,
                    'iters': iters + 1,
                    'state_dict': model.state_dict(),
                    'best_valid_accu': best_valid_accu,
                    'valid_accu': valid_accu,
                    'f_acc': f_acc,
                    'c_acc': c_acc,
                    'r_acc': r_acc,
                }, os.path.join(output_path, model_path))

                # III. save model best main
                if valid_accu > best_valid_accu:
                    best_valid_accu = valid_accu
                    print("Save Best Valid Accu")
                    model_path = "model_best.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))
                
                # III. save model best freq
                if f_acc > best_valid_freq:
                    best_valid_freq = f_acc
                    print("Save Best Valid Freq")
                    model_path = "model_best_freq.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))

                # III. save model best comm
                if c_acc > best_valid_comm:
                    best_valid_comm = c_acc
                    print("Save Best Valid Comm")
                    model_path = "model_best_comm.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))

                # III. save model best rare
                if r_acc > best_valid_rare:
                    best_valid_rare = r_acc
                    print("Save Best Valid Rare")
                    model_path = "model_best_rare.pt"
                    torch.save({
                        'epoch': epoch + 1,
                        'iters': iters + 1,
                        'state_dict': model.state_dict(),
                        'best_valid_accu': best_valid_accu,

                        'valid_accu': valid_accu,
                        'f_acc': f_acc,
                        'c_acc': c_acc,
                        'r_acc': r_acc,
                    }, os.path.join(output_path, model_path))

                # III. save model last
                model_path = "model_last.pt"
                torch.save({
                    'epoch': epoch + 1,
                    'iters': iters + 1,
                    'state_dict': model.state_dict(),
                    'best_valid_accu': best_valid_accu,
                    'optimizer' : optimizer.state_dict(),
                    'scheduler' : scheduler.state_dict(),

                    'valid_accu': valid_accu,
                    'f_acc': f_acc,
                    'c_acc': c_acc,
                    'r_acc': r_acc,

                    'best_valid_freq': best_valid_freq,
                    'best_valid_comm': best_valid_comm,
                    'best_valid_rare': best_valid_rare,

                    'Train_Loss_Iter': Train_Loss_Iter,
                    'Train_Accu_Iter': Train_Accu_Iter,

                    'Valid_Loss_Iter': Valid_Loss_Iter,
                    'Valid_Accu_Iter': Valid_Accu_Iter,

                    'Valid_Freq_Iter': Valid_Freq_Iter,
                    'Valid_Comm_Iter': Valid_Comm_Iter,
                    'Valid_Rare_Iter': Valid_Rare_Iter,

                    'Valid_Loss_Epoch': Valid_Loss_Epoch,
                    'Valid_Accu_Epoch': Valid_Accu_Epoch,

                    'Valid_Freq_Epoch': Valid_Freq_Epoch,
                    'Valid_Comm_Epoch': Valid_Comm_Epoch,
                    'Valid_Rare_Epoch': Valid_Rare_Epoch,

                }, os.path.join(output_path, model_path))
        iters = iters + 1

    ####################################################################################################
    ##### Epochwise evaluate on validation set 
    ####################################################################################################
    valid_loss = 0
    correct = 0
    valid_accu = 0
    predictions = []
    vl_category_list = []
    # switch to evaluate mode
    model.eval()
    with torch.no_grad():
        for i, (images, target) in enumerate(vl_loader):
            images = images.to(cfg['DEVICE'])
            target = target.to(cfg['DEVICE'])

            # compute output
            output = model(images)
            loss = criterion(output, target)

            # self-measurement
            valid_loss += criterion(output, target).item() # sum up batch loss
            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()
            predictions.extend(output.argmax(dim=-1).cpu().numpy().tolist())

            vl_category_list += [(target[i].item(), (output.argmax(dim=-1) == target)[i].float().item()) for i in range(output.shape[0])]

        ####################################################################################################
        ##### II. Print and Record Valid Log
        ####################################################################################################
        valid_loss /= len(vl_loader.dataset)
        valid_accu = 100. * correct / len(vl_loader.dataset)
        c_acc, f_acc, r_acc = count_acc_category(vl_category_list)
        print(f'\t\t====== | [VL] | EP = {epoch + 1:03d}/{num_epochs:03d} | ITER = {iters + 1:04d} | LOSS = {valid_loss:.4f} | ACC = {valid_accu:.4f} | ======')
        print(f'\t\t====== | [VL] | FREQ-ACC = {f_acc:.4f} | COMM-ACC = {c_acc:.4f} | RARE-ACC = {r_acc:.4f} | ======')
        
        Valid_Loss_Epoch.append(valid_loss)
        Valid_Accu_Epoch.append(valid_accu)

        Valid_Freq_Epoch.append(f_acc)
        Valid_Comm_Epoch.append(c_acc)
        Valid_Rare_Epoch.append(r_acc)

        ####################################################################################################
        ##### III. save Epoch_model | model_best_main | model_last
        ####################################################################################################
        model_path = ("Epoch%d_model_m_%.4f_f_%.4f_c_%.4f_r_%.4f.pt" % (epoch+1, valid_accu, f_acc, c_acc, r_acc))
        torch.save({
            'epoch': epoch + 1,
            'iters': iters + 1,
            'state_dict': model.state_dict(),
            'best_valid_accu': best_valid_accu,

            'valid_accu': valid_accu,
            'f_acc': f_acc,
            'c_acc': c_acc,
            'r_acc': r_acc,
            #'optimizer' : optimizer.state_dict(),
        }, os.path.join(output_path, model_path))

        if valid_accu > best_valid_accu:
            best_valid_accu = valid_accu
            print("Save Best Valid Accu")
            model_path = "model_best.pt"
            torch.save({
                'epoch': epoch + 1,
                'iters': iters + 1,
                'state_dict': model.state_dict(),
                'best_valid_accu': best_valid_accu,

                'valid_accu': valid_accu,
                'f_acc': f_acc,
                'c_acc': c_acc,
                'r_acc': r_acc,
            }, os.path.join(output_path, model_path))

        model_path = "model_last.pt"
        torch.save({
            'epoch': epoch + 1,
            'iters': iters + 1,
            'state_dict': model.state_dict(),
            'best_valid_accu': best_valid_accu,
            'optimizer' : optimizer.state_dict(),
            'scheduler' : scheduler.state_dict(),

            'valid_accu': valid_accu,
            'f_acc': f_acc,
            'c_acc': c_acc,
            'r_acc': r_acc,

            'best_valid_freq': best_valid_freq,
            'best_valid_comm': best_valid_comm,
            'best_valid_rare': best_valid_rare,

            'Train_Loss_Iter': Train_Loss_Iter,
            'Train_Accu_Iter': Train_Accu_Iter,

            'Valid_Loss_Iter': Valid_Loss_Iter,
            'Valid_Accu_Iter': Valid_Accu_Iter,

            'Valid_Freq_Iter': Valid_Freq_Iter,
            'Valid_Comm_Iter': Valid_Comm_Iter,
            'Valid_Rare_Iter': Valid_Rare_Iter,

            'Valid_Loss_Epoch': Valid_Loss_Epoch,
            'Valid_Accu_Epoch': Valid_Accu_Epoch,

            'Valid_Freq_Epoch': Valid_Freq_Epoch,
            'Valid_Comm_Epoch': Valid_Comm_Epoch,
            'Valid_Rare_Epoch': Valid_Rare_Epoch,

        }, os.path.join(output_path, model_path))